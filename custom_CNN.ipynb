{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import the packages",
   "id": "5bc7289a1f26e525"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ],
   "id": "9a62422959f8ef8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining a function for plotting the count of data against each class in each directory",
   "id": "5505cfcd66f7275a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plotData(dirPath):\n",
    "    \n",
    "    cats_cases_dir = dirPath + '/cats/'\n",
    "    dogs_cases_dir = dirPath + '/dogs/'\n",
    "\n",
    "    # Get the list of all the images\n",
    "    cats_cases_dir = glob.glob(cats_cases_dir + '*.jpg')\n",
    "    dogs_cases_dir = glob.glob(dogs_cases_dir + '*.jpg')\n",
    "\n",
    "    # An empty list. We will insert the data into this list in (img_path, label) format\n",
    "    data1 = []\n",
    "\n",
    "    # Go through all the cats images. The label for these cases will be 0\n",
    "    for img in cats_cases_dir:\n",
    "        data1.append((img, 'cats'))\n",
    "\n",
    "    # Go through all the dogs images. The label for these cases will be 1\n",
    "    for img in dogs_cases_dir:\n",
    "        data1.append((img, 'dogs'))\n",
    "\n",
    "    # Get a pandas dataframe from the data we have in our list\n",
    "    data1 = pd.DataFrame(data1, columns=['image', 'label'], index=None)\n",
    "\n",
    "    # Shuffle the data\n",
    "    data1 = data1.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    # Get the counts for each class\n",
    "    cases_count = data1['label'].value_counts()\n",
    "    print(cases_count)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=cases_count.index, y=cases_count.values)\n",
    "    plt.title('Number of cases', fontsize=14)\n",
    "    plt.xlabel('Case type', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(range(len(cases_count.index)), ['cats(cats)', 'dogs(dogs)'])\n",
    "    plt.show()"
   ],
   "id": "546af277851e4da7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# usage of plotting function",
   "id": "9e07435a7dcbdf96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plotData('data/train')\n",
    "plotData('data/test')\n",
    "plotData('data/valid')"
   ],
   "id": "fe56bd86cc875c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get few samples for both the classes",
   "id": "2dde9fdbd2bfb18d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cats_cases_dir = 'data/train/cats/'\n",
    "dogs_cases_dir = 'data/train/dogs/'\n",
    "\n",
    "# Get the list of all the images\n",
    "cats_cases_dir = glob.glob(cats_cases_dir + '*.jpg')\n",
    "dogs_cases_dir = glob.glob(dogs_cases_dir + '*.jpg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data1 = []\n",
    "\n",
    "# Go through all the cats images. The label for these cases will be 0\n",
    "for img in cats_cases_dir:\n",
    "    train_data1.append((img,0))\n",
    "\n",
    "# Go through all the dogs images. The label for these cases will be 1\n",
    "for img in dogs_cases_dir:\n",
    "    train_data1.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "train_data1 = pd.DataFrame(train_data1, columns=['image', 'label'],index=None)"
   ],
   "id": "bb59d726c8023416"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dogs_samples = (train_data1[train_data1['label']==1]['image'].iloc[:5]).tolist()\n",
    "cats_samples = (train_data1[train_data1['label']==0]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# Concat the data in a single list and del the above two list\n",
    "samples = dogs_samples + cats_samples\n",
    "del dogs_samples, cats_samples\n",
    "\n",
    "# Plot the data \n",
    "f, ax = plt.subplots(2,5, figsize=(30,10))\n",
    "for i in range(10):\n",
    "    img = cv2.imread(samples[i])\n",
    "    ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "    if i<5:\n",
    "        ax[i//5, i%5].set_title(\"cats\")\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title(\"dogs\")\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    ax[i//5, i%5].set_aspect('auto')\n",
    "plt.show()"
   ],
   "id": "26ae042dc88684a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining a method to get the number of files given a path",
   "id": "afa2861bc4a76a41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def retrieveNumberOfFiles(path): \n",
    "    cats_cases_dir = os.path.join(path, 'cats')\n",
    "    dogs_cases_dir = os.path.join(path, 'dogs')\n",
    "    list0 = os.listdir(cats_cases_dir) \n",
    "    list1 = os.listdir(dogs_cases_dir)  \n",
    "    return len(list0) , len(list1)"
   ],
   "id": "5b4d362a10ab7109"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# example of function usage",
   "id": "41c74d75369e3f9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "totalTrain = retrieveNumberOfFiles('data/train')[0] + retrieveNumberOfFiles('data/train')[1]\n",
    "totalVal = retrieveNumberOfFiles('data/valid')[0] + retrieveNumberOfFiles('data/valid')[1]\n",
    "totalTest = retrieveNumberOfFiles('data/test')[0] + retrieveNumberOfFiles('data/test')[1]\n",
    "print(totalTrain)"
   ],
   "id": "98804fb5c293c9ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize the training and valid data augmentation object",
   "id": "7aee0ca7619484d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1 / 255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# Initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\t'data/train',\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(244, 244),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=16)\n",
    "\n",
    "# for debugging usage\n",
    "for images, labels in trainGen: \n",
    "    print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\") \n",
    "    print(f\"Images dtype: {images.dtype}, Labels dtype: {labels.dtype}\")\n",
    "    break\n",
    "images, labels = next(trainGen)\n",
    "print(\"Images shape:\", images.shape)  # (16, 244, 244, 3)\n",
    "print(\"Labels shape:\", labels.shape)  # (16, num_classes)"
   ],
   "id": "77fabd7cea9d80a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "valAug = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "# Initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\t'data/valid',\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(244, 244),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=16)"
   ],
   "id": "7ad3356fe895fe96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\t'data/test',\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(244, 244),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=16)"
   ],
   "id": "c1ecefb73c12cc0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# building the custom CNN model",
   "id": "6a49e9e4b8e81afa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Importing packages\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# be sure about last layer output number should match num of class!\n",
    "class BC_Model:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "    \n",
    "        # Lets first initialize the model with input shape to be \"channels last\" and channel's dimension\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        # If we are using \"channels first\", then let's update the input shape and channel's dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        # (CONV2D => RELU => BN ) * 1 => POOL => DROPOUT\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV2D => RELU => BN ) * 2 => POOL => DROPOUT\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV2D => RELU => BN ) * 3 => POOL => DROPOUT\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV2D => RELU => BN ) * 4 => POOL => DROPOUT\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # FC => RELU layers => BN => DROPOUT\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        # Dense layer and softmax 'sigmoid' classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        # Returning the created network architecture\n",
    "        return model\n"
   ],
   "id": "2328709fc4038b0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# create object from the CNN model class",
   "id": "ed72ca740aaf712a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dogs_cats_cnn_model = BC_Model.build(width=244, height=244, depth=3, classes=2)\n",
    "# input shap for debugging\n",
    "print(dogs_cats_cnn_model.input_shape)\n",
    "print(dogs_cats_cnn_model.output_shape)"
   ],
   "id": "ca5f1944243953e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# compiling the model and setting learning rate with optimizer 'Adam'",
   "id": "29dacf07dfd9acce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "# integrate optimizer to CNN model\n",
    "dogs_cats_cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ],
   "id": "56bd466eb5f85409"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# setting hyperparameters for fitting the model (class_weight, check points,..)",
   "id": "96e4537424ad53f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate class weights\n",
    "\n",
    "train_counts = {'cats': retrieveNumberOfFiles('data/train')[0], 'dogs': retrieveNumberOfFiles('data/train')[1]}\n",
    "\n",
    "# Labels for the training set\n",
    "y_train = [0] * train_counts['cats'] + [1] * train_counts['dogs']  \n",
    "# 0 for cats, 1 for dogs\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Convert to dictionary format\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights: {class_weights_dict}\")"
   ],
   "id": "f958b0884815a8a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "checkpoint = ModelCheckpoint('best_model.keras', \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             mode='min', \n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               patience=10,  \n",
    "                               mode='min', \n",
    "                               verbose=1)"
   ],
   "id": "29cd6c59b6e10a58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# fitting the model",
   "id": "17ca669192f20f65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "steps_per_epoch = trainGen.samples // trainGen.batch_size\n",
    "validation_steps = valGen.samples // valGen.batch_size\n",
    "\n",
    "# Start training\n",
    "history = dogs_cats_cnn_model.fit(\n",
    "    trainGen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,  # specify the number of epochs you want\n",
    "    validation_data=valGen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint, early_stopping]  # include both callbacks\n",
    ")"
   ],
   "id": "69cc24ff65b709b3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# saving last epoch metrics\n",
    "dogs_cats_cnn_model.save('final_model.keras')"
   ],
   "id": "dc60d58cb9fc39de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plotting the model training process",
   "id": "18f740d298f0bee2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "id": "a573d60dc884eada"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# evaluate the Model using test set ('testGEN')",
   "id": "c1ac1333d05f9b48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate model performance on the test set\n",
    "test_loss, test_accuracy = dogs_cats_cnn_model.evaluate(\n",
    "    testGen, \n",
    "    steps=testGen.samples // testGen.batch_size)\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ],
   "id": "46218ce3bb02abf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# make predication using trained model",
   "id": "c4122aa514884fb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the best saved custom CNN model\n",
    "\n",
    "best_model = load_model(\"best_model.keras\")\n",
    "image_path = \"dog.jpg\"\n",
    "img = load_img(image_path, target_size=(244, 244))  # Use your input size\n",
    "img_array = img_to_array(img)  # Convert to numpy array\n",
    "img_array = img_array / 255.0  # Normalize if required\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get predictions (probabilities for each class)\n",
    "predictions = best_model.predict(img_array)\n",
    "\n",
    "# Extract probability of the predicted class\n",
    "predicted_class = np.argmax(predictions, axis=1)  # Class index\n",
    "predicted_probability = predictions[0][predicted_class[0]]  # Probability of that class\n",
    "print(testGen.class_indices)  # Dictionary mapping labels to indices\n",
    "print(f\"Predicted class: {predicted_class[0]}\")\n",
    "print(f\"Predicted probability: {predicted_probability:.2f}\")"
   ],
   "id": "30c534537805d5e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
